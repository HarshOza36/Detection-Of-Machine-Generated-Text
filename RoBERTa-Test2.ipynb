{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-04-27T02:54:02.369880Z","iopub.status.busy":"2023-04-27T02:54:02.369415Z","iopub.status.idle":"2023-04-27T02:54:08.127003Z","shell.execute_reply":"2023-04-27T02:54:08.125741Z","shell.execute_reply.started":"2023-04-27T02:54:02.369842Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import torchvision\n","import torchvision.utils as vutils\n","from torch.autograd import Variable\n","from tqdm.notebook import tqdm_notebook\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import torchvision.transforms as transforms\n","import random\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from pathlib import Path\n","from PIL import Image\n","import cv2\n","import time\n","from tqdm.notebook import tqdm_notebook\n","import time\n","import os, shutil\n","import matplotlib.animation as animation\n","from mpl_toolkits.axes_grid1 import ImageGrid\n","import sys, time\n","from nibabel.testing import data_path\n","import nibabel as nib\n","from PIL import Image\n","import scipy.ndimage as ndi\n","import itertools\n","import time\n","from transformers import AutoTokenizer, AutoModel\n","from torch.utils.data import DataLoader\n","from transformers import DataCollatorWithPadding\n","import tqdm\n","import nltk\n","nltk.download('punkt')\n","from sklearn.metrics import roc_auc_score"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-04-27T02:54:08.135384Z","iopub.status.busy":"2023-04-27T02:54:08.132166Z","iopub.status.idle":"2023-04-27T02:54:08.206159Z","shell.execute_reply":"2023-04-27T02:54:08.204823Z","shell.execute_reply.started":"2023-04-27T02:54:08.135334Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n","1\n"]}],"source":["print(torch.cuda.is_available())\n","print(torch.cuda.device_count())\n","device = torch.device(\"cuda\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-04-27T02:54:08.211093Z","iopub.status.busy":"2023-04-27T02:54:08.208879Z","iopub.status.idle":"2023-04-27T02:54:10.211979Z","shell.execute_reply":"2023-04-27T02:54:10.210740Z","shell.execute_reply.started":"2023-04-27T02:54:08.211051Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>What city in the United States has the highest...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>At work, wishing I was out on the boat</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A smile is a curve that sets everything straig...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Does sleep quality mediate the association bet...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>What city was found on the west bank of the ri...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            sentence  class\n","0  What city in the United States has the highest...      0\n","1            At work, wishing I was out on the boat       0\n","2  A smile is a curve that sets everything straig...      0\n","3  Does sleep quality mediate the association bet...      0\n","4  What city was found on the west bank of the ri...      0"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["data = pd.read_csv('/kaggle/input/dataset/FinalDataset.csv')\n","data.head()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-04-27T02:54:10.215862Z","iopub.status.busy":"2023-04-27T02:54:10.215370Z","iopub.status.idle":"2023-04-27T02:54:10.230820Z","shell.execute_reply":"2023-04-27T02:54:10.229487Z","shell.execute_reply.started":"2023-04-27T02:54:10.215824Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0    400015\n","1    376930\n","Name: class, dtype: int64"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["data['class'].value_counts()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-04-27T02:54:10.233283Z","iopub.status.busy":"2023-04-27T02:54:10.232675Z","iopub.status.idle":"2023-04-27T02:54:10.441571Z","shell.execute_reply":"2023-04-27T02:54:10.440496Z","shell.execute_reply.started":"2023-04-27T02:54:10.233245Z"},"trusted":true},"outputs":[],"source":["train_data, test_data = train_test_split(data, test_size=0.1, random_state=42)\n","train_data, val_data = train_test_split(train_data, test_size=0.1, random_state=42)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-04-27T02:54:10.444022Z","iopub.status.busy":"2023-04-27T02:54:10.443093Z","iopub.status.idle":"2023-04-27T02:54:10.454836Z","shell.execute_reply":"2023-04-27T02:54:10.453861Z","shell.execute_reply.started":"2023-04-27T02:54:10.443981Z"},"trusted":true},"outputs":[],"source":["# CREATE DATASET CLASS FOR DATALOADERS\n","class Dataset(Dataset):\n","    def __init__(self, dataframe):\n","        self.texts = dataframe['sentence'].values.tolist()\n","        self.labels = dataframe['class'].values.tolist()\n","        \n","    def __len__(self):\n","        return len(self.texts)\n","    \n","    def __getitem__(self, idx):\n","        X = self.texts[idx]\n","        y = self.labels[idx]\n","        X = X.lower()\n","        tokens = nltk.word_tokenize(X, language=\"english\")\n","        X = \" \".join(tokens)\n","        X = X.strip()\n","        \n","        return X, y"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-04-27T02:54:10.457112Z","iopub.status.busy":"2023-04-27T02:54:10.456563Z","iopub.status.idle":"2023-04-27T02:54:10.468068Z","shell.execute_reply":"2023-04-27T02:54:10.467031Z","shell.execute_reply.started":"2023-04-27T02:54:10.457072Z"},"trusted":true},"outputs":[],"source":["def collate_fn(batch):    \n","    x, y = [], []\n","    for text, label in batch:\n","        x.append(text)\n","        y.append(label)\n","    padded_text = tokenizer(x, padding=True, truncation=True, return_tensors='pt')\n","    \n","    return padded_text, torch.FloatTensor(y)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-04-27T02:54:10.469758Z","iopub.status.busy":"2023-04-27T02:54:10.469372Z","iopub.status.idle":"2023-04-27T02:54:10.479395Z","shell.execute_reply":"2023-04-27T02:54:10.478351Z","shell.execute_reply.started":"2023-04-27T02:54:10.469719Z"},"trusted":true},"outputs":[],"source":["class transformer(nn.Module):\n","    def __init__(self, base_model):\n","        super(transformer, self).__init__()\n","\n","        self.bert = base_model\n","        self.fc1 = nn.Linear(768, 32)\n","        self.fc2 = nn.Linear(32, 1)\n","\n","        self.relu = nn.ReLU()\n","        self.sigmoid = nn.Sigmoid()\n","        \n","    def forward(self, input_ids, attention_mask):\n","        bert_out = self.bert(input_ids=input_ids,\n","                             attention_mask=attention_mask)[0][:, 0]\n","        x = self.fc1(bert_out)\n","        x = self.relu(x)\n","        \n","        x = self.fc2(x)\n","        x = self.sigmoid(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-04-27T02:54:10.481443Z","iopub.status.busy":"2023-04-27T02:54:10.481074Z","iopub.status.idle":"2023-04-27T02:54:15.705047Z","shell.execute_reply":"2023-04-27T02:54:15.703912Z","shell.execute_reply.started":"2023-04-27T02:54:10.481407Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["torch.manual_seed(0)\n","\n","BERT_MODEL = \"roberta-base\"\n","tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL)\n","base_model = AutoModel.from_pretrained(BERT_MODEL)\n","\n","model = transformer(base_model)\n","model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# INFERENCE USING STORED MODEL\n","dataloader = DataLoader(Dataset(test_data), batch_size=16, num_workers=2, collate_fn=collate_fn)\n","model = torch.load('/kaggle/input/roberta-model/best_model.pt')\n","model.eval()\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n","total_acc_test = 0\n","total_loss_test = 0\n","for test_input, test_label in dataloader:\n","    attention_mask = test_input['attention_mask'].to(device)\n","    input_ids = test_input['input_ids'].squeeze(1).to(device)\n","\n","    test_label = test_label.to(device)\n","\n","    output = model(input_ids, attention_mask)\n","\n","    loss = criterion(output, test_label.float().unsqueeze(1))\n","\n","    total_loss_test += loss.item()\n","\n","    pred = (output >= 0.5).int()\n","    label = test_label.unsqueeze(1)\n","    auc_roc = roc_auc_score(label.cpu(), pred.cpu())\n","    total_acc_test += auc_roc\n","    \n","print(\"Test Loss:\", total_loss_test/len(dataloader))\n","print(\"Test AUCROC:\", total_acc_test/len(dataloader))"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-04-27T02:54:15.707564Z","iopub.status.busy":"2023-04-27T02:54:15.707144Z","iopub.status.idle":"2023-04-27T02:58:04.495324Z","shell.execute_reply":"2023-04-27T02:58:04.493962Z","shell.execute_reply.started":"2023-04-27T02:54:15.707520Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["For range of text length: 15-19\n","Test Loss: 0.1575334829810976\n","Test AUCROC: 0.9334783256599406\n","\n","For range of text length: 20-24\n","Test Loss: 0.12294149855628109\n","Test AUCROC: 0.9529911097168904\n","\n","For range of text length: 25-29\n","Test Loss: 0.10255630496321637\n","Test AUCROC: 0.9611482968766455\n","\n","For range of text length: 30-34\n","Test Loss: 0.08488206159668912\n","Test AUCROC: 0.9681443646736487\n","\n","For range of text length: 35-39\n","Test Loss: 0.08799995364241135\n","Test AUCROC: 0.9623507493877868\n","\n","For range of text length: 40-44\n","Test Loss: 0.11012367802976193\n","Test AUCROC: 0.9535503895197777\n","\n","For range of text length: 45-49\n","Test Loss: 0.12733520623107716\n","Test AUCROC: 0.9558049120549125\n","\n","For range of text length: 50-54\n","Test Loss: 0.12327423597853936\n","Test AUCROC: 0.9583351075154355\n","\n","For range of text length: 55-59\n","Test Loss: 0.1009333633849806\n","Test AUCROC: 0.9621628088464823\n","\n","For range of text length: 60-64\n","Test Loss: 0.08218827603969914\n","Test AUCROC: 0.9630297409143563\n","\n","For range of text length: 65-69\n","Test Loss: 0.06822668779770741\n","Test AUCROC: 0.9766394485144484\n","\n","For range of text length: 70-74\n","Test Loss: 0.05645119889633297\n","Test AUCROC: 0.9686706971189728\n","\n","For range of text length: 75-79\n","Test Loss: 0.0373310130621419\n","Test AUCROC: 0.9748488580385131\n","\n","For range of text length: 80-84\n","Test Loss: 0.028807457937891114\n","Test AUCROC: 0.9704022988505747\n","\n","For range of text length: 85-89\n","Test Loss: 0.02878687701063584\n","Test AUCROC: 0.974741063534167\n","\n","For range of text length: 90-94\n","Test Loss: 0.013778677527235621\n","Test AUCROC: 0.9523809523809523\n","\n","For range of text length: 95-99\n","Test Loss: 0.02508000764355529\n","Test AUCROC: 0.9333333333333333\n","\n","For range of text length: 100-104\n","Test Loss: 0.011077417573233106\n","Test AUCROC: 0.9979166666666667\n","\n","For range of text length: 105-109\n","Test Loss: 0.0010846111591407944\n","Test AUCROC: 1.0\n","\n","For range of text length: 110-114\n","Test Loss: 0.011873159520161738\n","Test AUCROC: 1.0\n","\n","For range of text length: 115-119\n","Test Loss: 0.005473176895369154\n","Test AUCROC: 1.0\n","\n","For range of text length: 120-124\n","Test Loss: 0.0032284864800102594\n","Test AUCROC: 1.0\n","\n","For range of text length: 125-129\n","Test Loss: 0.03562457106454531\n","Test AUCROC: 0.875\n","\n","For range of text length: 130-134\n","Test Loss: 0.0033263098885072395\n","Test AUCROC: 1.0\n","\n","For range of text length: 135-139\n","Test Loss: 0.0070441871212096885\n","Test AUCROC: 1.0\n","\n","For range of text length: 140-144\n","Test Loss: 0.00198506198648829\n","Test AUCROC: 1.0\n","\n","For range of text length: 150-154\n","Test Loss: 0.009725811491080094\n","Test AUCROC: 1.0\n","\n","For range of text length: 155-159\n","Test Loss: 0.0012970471128435999\n","Test AUCROC: 1.0\n","\n","For range of text length: 170-174\n","Test Loss: 0.000519734516274184\n","Test AUCROC: 1.0\n","\n","For range of text length: 185-189\n","Test Loss: 0.01809414103627205\n","Test AUCROC: 1.0\n","\n","For range of text length: 200-204\n","Test Loss: 0.05887577606232038\n","Test AUCROC: 0.943452380952381\n","\n"]}],"source":["data = {}\n","count = 0\n","errors = []\n","model = torch.load('/kaggle/input/roberta-model/best_model.pt')\n","model.eval()\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n","def getRangeRows(df, x, y):\n","    df['word_lengths'] = df['sentence'].apply(lambda x: len(x.split(\" \")))\n","    df = df[(df['word_lengths'] >= x) & (df['word_lengths'] <= y)]\n","    return df\n","start = 10\n","while start != 200:\n","    if start == 195:\n","        newDf = getRangeRows(test_data, start, 200)\n","    else:\n","        newDf = getRangeRows(test_data, start, start + 4)\n","    start += 5\n","    count = 0\n","    # INFERENCE USING STORED MODEL\n","    dataloader = DataLoader(Dataset(newDf), batch_size=16, num_workers=2, collate_fn=collate_fn)\n","    total_acc_test = 0\n","    total_loss_test = 0\n","    for test_input, test_label in dataloader:\n","        attention_mask = test_input['attention_mask'].to(device)\n","        input_ids = test_input['input_ids'].squeeze(1).to(device)\n","\n","        test_label = test_label.to(device)\n","\n","        output = model(input_ids, attention_mask)\n","\n","        loss = criterion(output, test_label.float().unsqueeze(1))\n","\n","        total_loss_test += loss.item()\n","\n","        pred = (output >= 0.5).int()\n","        label = test_label.unsqueeze(1)\n","        try:\n","            auc_roc = roc_auc_score(label.cpu(), pred.cpu())\n","        except:\n","            count += 1\n","            key = str(start) + '-' + str(start + 4)\n","            errors.append([key, count])\n","            continue\n","        total_acc_test += auc_roc\n","        \n","    key = str(start) + '-' + str(start + 4)\n","    try:\n","        test_loss = total_loss_test/(len(dataloader) - count)\n","        test_aucroc = total_acc_test/(len(dataloader) - count)\n","        print(\"For range of text length:\", key)\n","        print(\"Test Loss:\", test_loss)\n","        print(\"Test AUCROC:\", test_aucroc)\n","        print()\n","    except:\n","        continue\n","    data[key] = test_aucroc"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
